---
layout: post
title: Understanding GANs fundamentally through a statistical divergence perspective
published: true
---

Most introductions to Generative adversarial networks (GAN) focus on a game-theoretic perspective with two players where one player (the discriminator) tries to differentiate the real data from the fake data while the other player (the generator) learns to generate realistic data by trying to "fool" the discriminator. However, this view of GANs is very limited as it does not generalize to GANs other than one initially formulated by Goodfellow et al. (2014). 

After reading a lot on the subject through many dense papers, I started making sense of what GANs are fundamentally. Most researchers specialized in GANs already know this but the majority of ML-enthusiasts probably don't and some GAN papers suggest that a few authors don't understand this well so I thought it would be really useful to lay out a short summary of this perspective on the subject.

Let start from a simple problem, let say we want to minimize the distance between an object in $\mathbb{R}^n$ and an object generated by a neural network (assuming a fixed input so that the neural network always generate the same thing). The solution is to minimize some sort of distance between the two objects until we reach convergence. A slightly harder problem would be to minimize the distance between a set of objects and another set of objects generated by a neural network, however, this would make the assumption that all our real data is the only data possible (exhausting cases). In GANs we assume that the real data comes from an underlying probability distribution $P$ and that the data generated by the generator comes from an underlying probability distribution $Q_{\theta}$ (produced by a neural network); we seek to minimize the distance between the two probability distributions $P$ and $Q_{\theta}$. But how do we even do this and why is there a min-max?